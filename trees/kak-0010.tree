\date{2024-11-22}
\title{Value Function}
\taxon{definition}

\p{
For a fixed policy and a starting state #{s_{0}=s}, we define the value function #{V_{M}^{s}:S\to\mathbb{R}} as the discounted sum of future rewards

##{V_{M}^{s}(s)=\mathbb{E}\Big[\sum_{t=0}^{\infty}\gamma^{t}r(s_{t},a_{t})\mid\pi,s_{0}=s\Big]}
}
