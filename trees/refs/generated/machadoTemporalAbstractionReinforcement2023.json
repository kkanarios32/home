[{"URL": "https://arxiv.org/abs/2110.05740", "abstract": "Reasoning at multiple levels of temporal abstraction is one of the key attributes of intelligence. In reinforcement learning, this is often modeled through temporally extended courses of actions called options. Options allow agents to make predictions and to operate at different levels of abstraction within an environment. Nevertheless, approaches based on the options framework often start with the assumption that a reasonable set of options is known beforehand. When this is not the case, there are no definitive answers for which options one should consider. In this paper, we argue that the successor representation, which encodes states based on the pattern of state visitation that follows them, can be seen as a natural substrate for the discovery and use of temporal abstractions. To support our claim, we take a big picture view of recent results, showing how the successor representation can be used to discover options that facilitate either temporally-extended exploration or planning. We cast these results as instantiations of a general framework for option discovery in which the agent\u2019s representation is used to identify useful options, which are then used to further improve its representation. This results in a virtuous, never-ending, cycle in which both the representation and the options are constantly refined based on each other. Beyond option discovery itself, we also discuss how the successor representation allows us to augment a set of options into a combinatorially large counterpart without additional learning. This is achieved through the combination of previously learned options. Our empirical evaluation focuses on options discovered for temporally-extended exploration and on the use of the successor representation to combine them. Our results shed light on important design decisions involved in the definition of options and demonstrate the synergy of different methods based on the successor representation, such as eigenoptions and the option keyboard.", "accessed": {"date-parts": [[2024, 10, 18]]}, "author": [{"family": "Machado", "given": "Marlos C."}, {"family": "Barreto", "given": "Andre"}, {"family": "Precup", "given": "Doina"}, {"family": "Bowling", "given": "Michael"}], "id": "machadoTemporalAbstractionReinforcement2023", "issued": {"date-parts": [[2023, 4]]}, "keyword": "Computer Science - Artificial Intelligence,Computer Science - Machine Learning", "language": "en-US", "number": "arXiv:2110.05740", "publisher": "arXiv", "title": "Temporal Abstraction in Reinforcement Learning with the Successor Representation", "type": "", "original_bibtex": "@misc{machadoTemporalAbstractionReinforcement2023,\n title = {Temporal {{Abstraction}} in {{Reinforcement Learning}} with the {{Successor Representation}}},\n author = {Machado, Marlos C. and Barreto, Andre and Precup, Doina and Bowling, Michael},\n year = {2023},\n urldate = {2024-10-18},\n number = {arXiv:2110.05740},\n publisher = {arXiv},\n file = {/home/kellen/Zotero/storage/PEJ6S5ZX/Machado et al. - 2023 - Temporal Abstraction in Reinforcement Learning with the Successor Representation.pdf},\n keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {Reasoning at multiple levels of temporal abstraction is one of the key attributes of intelligence. In reinforcement learning, this is often modeled through temporally extended courses of actions called options. Options allow agents to make predictions and to operate at different levels of abstraction within an environment. Nevertheless, approaches based on the options framework often start with the assumption that a reasonable set of options is known beforehand. When this is not the case, there are no definitive answers for which options one should consider. In this paper, we argue that the successor representation, which encodes states based on the pattern of state visitation that follows them, can be seen as a natural substrate for the discovery and use of temporal abstractions. To support our claim, we take a big picture view of recent results, showing how the successor representation can be used to discover options that facilitate either temporally-extended exploration or planning. We cast these results as instantiations of a general framework for option discovery in which the agent's representation is used to identify useful options, which are then used to further improve its representation. This results in a virtuous, never-ending, cycle in which both the representation and the options are constantly refined based on each other. Beyond option discovery itself, we also discuss how the successor representation allows us to augment a set of options into a combinatorially large counterpart without additional learning. This is achieved through the combination of previously learned options. Our empirical evaluation focuses on options discovered for temporally-extended exploration and on the use of the successor representation to combine them. Our results shed light on important design decisions involved in the definition of options and demonstrate the synergy of different methods based on the successor representation, such as eigenoptions and the option keyboard.},\n primaryclass = {cs},\n eprint = {2110.05740},\n month = {April}\n}\n"}]