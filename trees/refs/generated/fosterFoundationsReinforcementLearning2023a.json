[{"DOI": "10.48550/arXiv.2312.16730", "URL": "https://arxiv.org/abs/2312.16730", "abstract": "These lecture notes give a statistical perspective on the foundations of reinforcement learning and interactive decision making. We present a unifying framework for addressing the exploration-exploitation dilemma using frequentist and Bayesian approaches, with connections and parallels between supervised learning/estimation and decision making as an overarching theme. Special attention is paid to function approximation and flexible model classes such as neural networks. Topics covered include multi-armed and contextual bandits, structured bandits, and reinforcement learning with high-dimensional feedback.", "accessed": {"date-parts": [[2025, 1, 23]]}, "author": [{"family": "Foster", "given": "Dylan J."}, {"family": "Rakhlin", "given": "Alexander"}], "id": "fosterFoundationsReinforcementLearning2023a", "issued": {"date-parts": [[2023, 12]]}, "keyword": "Computer Science - Machine Learning,Mathematics - Optimization and Control,Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Statistics Theory", "number": "arXiv:2312.16730", "publisher": "arXiv", "title": "Foundations of Reinforcement Learning and Interactive Decision Making", "type": "", "original_bibtex": "@misc{fosterFoundationsReinforcementLearning2023a,\n title = {Foundations of {{Reinforcement Learning}} and {{Interactive Decision Making}}},\n author = {Foster, Dylan J. and Rakhlin, Alexander},\n year = {2023},\n doi = {10.48550/arXiv.2312.16730},\n urldate = {2025-01-23},\n number = {arXiv:2312.16730},\n publisher = {arXiv},\n file = {/home/kellen/Zotero/storage/EFVPRXIJ/Foster and Rakhlin - 2023 - Foundations of Reinforcement Learning and Interactive Decision Making.pdf;/home/kellen/Zotero/storage/GJCWUBT3/2312.html},\n keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Statistics Theory},\n archiveprefix = {arXiv},\n abstract = {These lecture notes give a statistical perspective on the foundations of reinforcement learning and interactive decision making. We present a unifying framework for addressing the exploration-exploitation dilemma using frequentist and Bayesian approaches, with connections and parallels between supervised learning/estimation and decision making as an overarching theme. Special attention is paid to function approximation and flexible model classes such as neural networks. Topics covered include multi-armed and contextual bandits, structured bandits, and reinforcement learning with high-dimensional feedback.},\n primaryclass = {cs},\n eprint = {2312.16730},\n month = {December}\n}\n"}]