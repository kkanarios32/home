[{"URL": "https://arxiv.org/abs/2405.15116", "abstract": "Recent advances in large language models have shown capabilities that are extraordinary and near-superhuman. These models operate with such complexity that reliably evaluating and aligning them proves challenging for humans. This leads to the natural question: can guidance from weak models (like humans) adequately direct the capabilities of strong models? In a recent and somewhat surprising work, Burns et al. [BIK+23] empirically demonstrated that when strong models (like GPT-4) are finetuned using labels generated by weak supervisors (like GPT-2), the strong models outperform their weaker counterparts\u2014a phenomenon they term weak-to-strong generalization.", "accessed": {"date-parts": [[2024, 10, 24]]}, "author": [{"family": "Charikar", "given": "Moses"}, {"family": "Pabbaraju", "given": "Chirag"}, {"family": "Shiragur", "given": "Kirankumar"}], "id": "charikarQuantifyingGainWeakStrong2024", "issued": {"date-parts": [[2024, 10]]}, "keyword": "Computer Science - Artificial Intelligence,Computer Science - Machine Learning", "language": "en-US", "number": "arXiv:2405.15116", "publisher": "arXiv", "title": "Quantifying the Gain in Weak-to-Strong Generalization", "type": "", "original_bibtex": "@misc{charikarQuantifyingGainWeakStrong2024,\n title = {Quantifying the {{Gain}} in {{Weak-to-Strong Generalization}}},\n author = {Charikar, Moses and Pabbaraju, Chirag and Shiragur, Kirankumar},\n year = {2024},\n urldate = {2024-10-24},\n number = {arXiv:2405.15116},\n publisher = {arXiv},\n file = {/home/kellen/Zotero/storage/Y3LYJ8Q8/Charikar et al. - 2024 - Quantifying the Gain in Weak-to-Strong Generalization.pdf},\n keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {Recent advances in large language models have shown capabilities that are extraordinary and near-superhuman. These models operate with such complexity that reliably evaluating and aligning them proves challenging for humans. This leads to the natural question: can guidance from weak models (like humans) adequately direct the capabilities of strong models? In a recent and somewhat surprising work, Burns et al. [BIK+23] empirically demonstrated that when strong models (like GPT-4) are finetuned using labels generated by weak supervisors (like GPT-2), the strong models outperform their weaker counterparts---a phenomenon they term weak-to-strong generalization.},\n primaryclass = {cs},\n eprint = {2405.15116},\n month = {October}\n}\n"}]