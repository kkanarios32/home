[{"URL": "https://arxiv.org/abs/2301.13062", "abstract": "Machine learning (ML) compilers are an active area of research because they offer the potential to automatically speedup tensor programs. Kernel fusion is often cited as an important optimization performed by ML compilers. However, there exists a knowledge gap about how XLA, the most common ML compiler, applies this nuanced optimization, what kind of speedup it can afford, and what low-level effects it has on hardware. Our paper aims to bridge this knowledge gap by studying key compiler passes of XLA\u2019s source code. Our evaluation on a reinforcement learning environment Cartpole shows how different fusion decisions in XLA are made in practice. Furthermore, we implement several XLA kernel fusion strategies that can achieve up to 10.56x speedup compared to our baseline implementation.", "accessed": {"date-parts": [[2024, 10, 20]]}, "author": [{"family": "Snider", "given": "Daniel"}, {"family": "Liang", "given": "Ruofan"}], "id": "sniderOperatorFusionXLA2023", "issued": {"date-parts": [[2023, 1]]}, "keyword": "Computer Science - Machine Learning", "language": "en-US", "number": "arXiv:2301.13062", "publisher": "arXiv", "title": "Operator Fusion in XLA: Analysis and Evaluation", "title-short": "Operator Fusion in XLA", "type": "", "original_bibtex": "@misc{sniderOperatorFusionXLA2023,\n title = {Operator {{Fusion}} in {{XLA}}: {{Analysis}} and {{Evaluation}}},\n author = {Snider, Daniel and Liang, Ruofan},\n year = {2023},\n urldate = {2024-10-20},\n number = {arXiv:2301.13062},\n publisher = {arXiv},\n file = {/home/kellen/Zotero/storage/9M5P2JQF/Snider and Liang - 2023 - Operator Fusion in XLA Analysis and Evaluation.pdf},\n keywords = {Computer Science - Machine Learning},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {Machine learning (ML) compilers are an active area of research because they offer the potential to automatically speedup tensor programs. Kernel fusion is often cited as an important optimization performed by ML compilers. However, there exists a knowledge gap about how XLA, the most common ML compiler, applies this nuanced optimization, what kind of speedup it can afford, and what low-level effects it has on hardware. Our paper aims to bridge this knowledge gap by studying key compiler passes of XLA's source code. Our evaluation on a reinforcement learning environment Cartpole shows how different fusion decisions in XLA are made in practice. Furthermore, we implement several XLA kernel fusion strategies that can achieve up to 10.56x speedup compared to our baseline implementation.},\n primaryclass = {cs},\n eprint = {2301.13062},\n month = {January},\n shorttitle = {Operator {{Fusion}} in {{XLA}}}\n}\n"}]