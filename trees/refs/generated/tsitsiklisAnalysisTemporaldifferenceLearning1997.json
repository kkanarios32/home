[{"DOI": "10.1109/9.580874", "ISSN": "00189286", "abstract": "We discuss the temporal-difference learning algorithm, as applied to approximating the cost-to-go function of an infinite-horizon discounted Markov chain. The algorithm we analyze updates parameters of a linear function approximator online during a single endless trajectory of an irreducible aperiodic Markov chain with a finite or infinite state space. We present a proof of convergence (with probability one), a characterization of the limit of convergence, and a bound on the resulting approximation error. Furthermore, our analysis is based on a new line of reasoning that provides new intuition about the dynamics of temporal-difference learning.", "accessed": {"date-parts": [[2025, 1, 16]]}, "author": [{"family": "Tsitsiklis", "given": "J. N."}, {"family": "Van Roy", "given": "B."}], "container-title": "IEEE Transactions on Automatic Control", "id": "tsitsiklisAnalysisTemporaldifferenceLearning1997", "issue": "5", "issued": {"date-parts": [[1997, 5]]}, "language": "en-US", "page": "674-690", "title": "An analysis of temporal-difference learning with function approximation", "type": "article-journal", "volume": "42", "original_bibtex": "@article{tsitsiklisAnalysisTemporaldifferenceLearning1997,\n title = {An Analysis of Temporal-Difference Learning with Function Approximation},\n author = {Tsitsiklis, J.N. and Van Roy, B.},\n year = {1997},\n doi = {10.1109/9.580874},\n urldate = {2025-01-16},\n journal = {IEEE Transactions on Automatic Control},\n volume = {42},\n number = {5},\n pages = {674--690},\n file = {/home/kellen/Zotero/storage/58WIJRVR/Tsitsiklis and Van Roy - 1997 - An analysis of temporal-difference learning with function approximation.pdf},\n langid = {english},\n copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},\n abstract = {We discuss the temporal-difference learning algorithm, as applied to approximating the cost-to-go function of an infinite-horizon discounted Markov chain. The algorithm we analyze updates parameters of a linear function approximator online during a single endless trajectory of an irreducible aperiodic Markov chain with a finite or infinite state space. We present a proof of convergence (with probability one), a characterization of the limit of convergence, and a bound on the resulting approximation error. Furthermore, our analysis is based on a new line of reasoning that provides new intuition about the dynamics of temporal-difference learning.},\n issn = {00189286},\n month = {May}\n}\n"}]